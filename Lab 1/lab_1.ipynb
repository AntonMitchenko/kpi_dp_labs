{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f19ed69",
   "metadata": {},
   "source": [
    "# Лабораторна робота №1 \n",
    "## Мітченко Антона КМ-03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d6e7e",
   "metadata": {},
   "source": [
    "## **Завдання 1:**\n",
    "розробити програмне забезпечення для реалізації\n",
    "класичного нейрону. Передбачити режим навчання на одному навчальному прикладі\n",
    "та режим розпізнавання.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0d20ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Імпорт бібліотек\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from numpy import exp, array, random, dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae622a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00716971]\n"
     ]
    }
   ],
   "source": [
    "# Визначення вхідних даних для навчального набору\n",
    "training_set_inputs = array([[0, 0, 1]])\n",
    "\n",
    "# Визначення вихідних даних для навчального набору та транспонування їх\n",
    "training_set_outputs = array([[0]]).T\n",
    "\n",
    "# Ініціалізація вагових коефіцієнтів нейронної мережі випадковими значеннями\n",
    "random.seed(1)\n",
    "synaptic_weights = 2 * random.random((3, 1)) - 1\n",
    "\n",
    "# Навчання нейронної мережі (в даному випадку - 10000 ітерацій)\n",
    "for iteration in range(10000):\n",
    "    # Обчислення вихідних значень нейрону за допомогою функції сигмоїди\n",
    "    output = 1 / (1 + exp(-(dot(training_set_inputs, synaptic_weights))))\n",
    "    \n",
    "    # Коригування вагових коефіцієнтів нейрону на основі отриманих результатів\n",
    "    synaptic_weights += dot(training_set_inputs.T, (training_set_outputs - output) * output * (1 - output))\n",
    "\n",
    "# Виведення прогнозу для нових даних\n",
    "new_input = array([0, 0, 1])\n",
    "predicted_output = 1 / (1 + exp(-(dot(new_input, synaptic_weights))))\n",
    "print(predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f1204",
   "metadata": {},
   "source": [
    "## Інший варіант виконання 1го завдання "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53adb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Даємо визначення сигмоїдної функції активації\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb50427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визначаємо похідну сигмоїдної функції\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9a5844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input 6, predicted output: 1.00\n"
     ]
    }
   ],
   "source": [
    "class ClassicNeuron:\n",
    "    def __init__(self):\n",
    "        # Ініціалізуємо випадкові ваги та поріг\n",
    "        self.weights = np.random.uniform(size=(1, 1))\n",
    "        self.bias = np.random.uniform()\n",
    "\n",
    "    def train(self, X_train, y_train, learning_rate, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            # Проходимо через всі навчальні дані\n",
    "            for i in range(len(X_train)):\n",
    "                # Вираховуємо вагований вхід та відповідь\n",
    "                weighted_sum = np.dot(X_train[i], self.weights) + self.bias\n",
    "                prediction = sigmoid(weighted_sum)\n",
    "\n",
    "                # Рахуємо помилку\n",
    "                error = y_train[i] - prediction\n",
    "\n",
    "                # Обчислюємо внутрішню помилку (похідна помножена на помилку)\n",
    "                d_error = error * sigmoid_derivative(prediction)\n",
    "\n",
    "                # Оновлюємо ваги та поріг\n",
    "                self.weights += learning_rate * np.dot(X_train[i].reshape(-1, 1), d_error)\n",
    "                self.bias += learning_rate * d_error\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        weighted_sum = np.dot(X_test, self.weights) + self.bias\n",
    "        prediction = sigmoid(weighted_sum)\n",
    "        return prediction\n",
    "\n",
    "# Навчальні дані (приклад: x=4, y=1)\n",
    "X_train = np.array([[4]])\n",
    "y_train = np.array([[1]])\n",
    "\n",
    "# Створюємо класичний нейрон\n",
    "neuron = ClassicNeuron()\n",
    "\n",
    "# Навчаємо нейрон\n",
    "neuron.train(X_train, y_train, learning_rate=0.1, epochs=10000)\n",
    "\n",
    "# Режим розпізнавання\n",
    "X_test = np.array([[6]])  # Вхід для розпізнавання\n",
    "prediction = neuron.predict(X_test)\n",
    "\n",
    "print(f\"For input {X_test[0][0]}, predicted output: {prediction[0][0]:.2f}\")\n",
    "#У цьому коді ми створюємо клас ClassicNeuron, який містить методи для навчання та розпізнавання. Ми навчаємо класичний нейрон на одному навчальному прикладі (x=2, y=0) і після навчання використовуємо його для розпізнавання в режимі розпізнавання (для x=3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ff552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функція для здійснення прогнозу з нейронної мережі\n",
    "# x: Вхідні дані (вектор)\n",
    "def predict(x):\n",
    "    # Обчислення входу до прихованого шару\n",
    "    hidden_layer_input = np.dot(x, weights_input_hidden) + bias_hidden\n",
    "    \n",
    "    # Застосування активаційної функції (сигмоїда) до входу прихованого шару\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    # Обчислення входу до вихідного шару\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    \n",
    "    # Застосування активаційної функції (сигмоїда) до входу вихідного шару\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Повернення вихідних значень вихідного шару (прогноз)\n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ed7ce",
   "metadata": {},
   "source": [
    "## **Завдання 2**\n",
    "Завдання: розробити програмне забезпечення для реалізації\n",
    "елементарного двошарового персептрону із структурою 1-1-1. Передбачити режим навчання\n",
    "на одному навчальному прикладі та режим розпізнавання.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3e65619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input 0.75, predicted output: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Визначимо навчальні дані: вхідні (x) і цільові (y) значення\n",
    "X_train = np.array([[0.5]])  # Input (x)\n",
    "y_train = np.array([[1]])    # Target (y) for y = 2x\n",
    "\n",
    "# Встановлюємо випадкове початкове число для відтворюваності\n",
    "np.random.seed(42)\n",
    "\n",
    "# Ініціалізація ваги та зміщення випадковим чином\n",
    "input_neurons = 1\n",
    "hidden_neurons = 1\n",
    "output_neurons = 1\n",
    "\n",
    "weights_input_hidden = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
    "weights_hidden_output = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
    "\n",
    "bias_hidden = np.random.uniform(size=(1, hidden_neurons))\n",
    "bias_output = np.random.uniform(size=(1, output_neurons))\n",
    "\n",
    "# Встановлюємо швидкість навчання\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Тренування персептрона\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    hidden_layer_input = np.dot(X_train, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Calculate the error\n",
    "    error = y_train - output_layer_output\n",
    "\n",
    "    # Зворотне поширення\n",
    "    d_output = error * sigmoid_derivative(output_layer_output)\n",
    "    error_hidden_layer = d_output.dot(weights_hidden_output.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    # Оноввлюємо ваги та зміщення\n",
    "    weights_hidden_output += hidden_layer_output.T.dot(d_output) * learning_rate\n",
    "    weights_input_hidden += X_train.T.dot(d_hidden_layer) * learning_rate\n",
    "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
    "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "\n",
    "x_test = np.array([[0.75]])  # Test input\n",
    "prediction = predict(x_test)\n",
    "\n",
    "print(f\"For input {x_test[0][0]}, predicted output: {prediction[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d59c72",
   "metadata": {},
   "source": [
    "## **Завдання 3**\n",
    "Завдання: розробити програмне забезпечення для реалізації\n",
    "двошарового персептрону із структурою 2-3-1. Передбачити режим навчання «ON-LINE» та режим розпізнавання.\n",
    "\n",
    "\n",
    "Піддослідна функція х1+х2=у\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5c37fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input [0 0], predicted output: 0.04 (Actual: 0)\n",
      "For input [0 1], predicted output: 0.99 (Actual: 1)\n",
      "For input [1 0], predicted output: 0.99 (Actual: 1)\n",
      "For input [1 1], predicted output: 1.00 (Actual: 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input features (x1 and x2)\n",
    "y_train = np.array([[0], [1], [1], [2]])  # Corresponding labels (y = x1 + x2)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "input_neurons = 2\n",
    "hidden_neurons = 3\n",
    "output_neurons = 1\n",
    "\n",
    "weights_input_hidden = np.random.uniform(size=(input_neurons, hidden_neurons))\n",
    "weights_hidden_output = np.random.uniform(size=(hidden_neurons, output_neurons))\n",
    "\n",
    "bias_hidden = np.random.uniform(size=(1, hidden_neurons))\n",
    "bias_output = np.random.uniform(size=(1, output_neurons))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        \n",
    "        input_data = X_train[i]\n",
    "        hidden_layer_input = np.dot(input_data, weights_input_hidden) + bias_hidden\n",
    "        hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "        output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "        error = y_train[i] - output_layer_output\n",
    "\n",
    "        d_output = error * sigmoid_derivative(output_layer_output)\n",
    "        error_hidden_layer = d_output.dot(weights_hidden_output.T)\n",
    "        d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "        weights_hidden_output += np.outer(hidden_layer_output, d_output) * learning_rate\n",
    "        weights_input_hidden += np.outer(input_data, d_hidden_layer) * learning_rate\n",
    "        bias_output += d_output * learning_rate\n",
    "        bias_hidden += d_hidden_layer * learning_rate\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    input_data = X_train[i]\n",
    "    prediction = predict(input_data)\n",
    "    print(f\"For input {input_data}, predicted output: {prediction[0][0]:.2f} (Actual: {y_train[i][0]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
